{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Steps in a Machine Learning Task\n",
    "\n",
    "1. **Data Preprocessing**\n",
    "   - Standardize data formats\n",
    "   - Remove outliers and invalid data\n",
    "   - Apply necessary data transformations\n",
    "   - Split the dataset into training, validation, and test sets\n",
    "     - Tools: `train_test_split` and `KFold` from scikit-learn\n",
    "\n",
    "2. **Model Selection**\n",
    "   - Choose an appropriate model for the task\n",
    "   - Define the loss function and optimization method\n",
    "   - Set relevant hyperparameters\n",
    "   - Many machine learning libraries (e.g., scikit-learn) provide built-in loss functions and optimizers\n",
    "\n",
    "3. **Model Training and Evaluation**\n",
    "   - Fit the model to the training data\n",
    "   - Evaluate model performance on the validation and/or test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Work for Deep Learning\n",
    "- Data Loaders for batch training\n",
    "- Models layer by layer, often using custom or specialized layers\n",
    "- Ensure loss functions and optimizers support backpropagation for user-defined architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 16   # mach batch contains 16 samples\n",
    "lr = 1e-4         # learning rate\n",
    "max_epochs = 100\n",
    "\"\"\"Hyperparameters can also be stored in yaml, json, dict or other files\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU calling\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'  # PyTorch can only access to GPU 0 and 1\n",
    "device = torch.device(                       # Prioritize using GPU 1\n",
    "                    'cuda:1' \\               \n",
    "                    if torch.cuda.is_available() \\\n",
    "                    else 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from torchvision import datasets\n",
    "train_data = datasets.ImageFolder(\n",
    "    train_path,\n",
    "    transform=data_transform)   # data_transform enables image cropping, flipping, etc.\n",
    "val_data = datasets.ImageFolder(val_path, transform=data_transform)\n",
    "\n",
    "# Customize Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            annotations_file (string): Path to the csv file with annotations.\n",
    "            img_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            target_transform (callable, optional): Optional transform to be applied\n",
    "                on the target.\n",
    "        \"\"\"\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):             # return the number of samples in the dataset\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):    # allows the dataset object to be indexed like a list (e.g., dataset[idx]). It returns a single sample and its label.\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx (int): Index\n",
    "        \"\"\"\n",
    "        img_path = os.path.join(           # constructs the full file path to the image by joining the image directory and the image filename\n",
    "            self.img_dir,                  # which is retrieved from the first column of the img_labels DataFrame at row idx\n",
    "            self.img_labels.iloc[idx, 0]\n",
    "            )   (self.img_dir) and the image filename \n",
    "        image = read_image(img_path)           \n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,  # 4 or 8 for Linux, 0 for Windows\n",
    "    shuffle=True,   # normally True for training, False for validation\n",
    "    drop_last=True  # forego the last sample if its size is less than batch_size\n",
    "    )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,\n",
    "    shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):   # MLP for \"Multi-Layer Perceptron\"\n",
    "    # claim the layers with model parameters, here are two fully connected layers\n",
    "    def __init__(self, **kwargs):\n",
    "        # call the constructor of the parent class MLP to perform necessary initialization. This allows additional functions to be specified when constructing an instance\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.hidden = nn.Linear(784, 256)   # Linear means fully connected layer; 784 features from the input image, 256 features for the hidden layer\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(256,10)     # 256 features for the output layer, 10 features for the output\n",
    "\n",
    "    def forward(self, x):\n",
    "        o = self.act(self.hidden(x))\n",
    "        return self.output(o)   \n",
    "    \n",
    "    '''\n",
    "    No need to define the back propagation function, because\n",
    "    PyTorch will automatically compute the gradients for the parameters during the forward pass.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(2,784) # \n",
    "net = MLP()   # instantiate the model, i.e. create a new MLP object\n",
    "print(net)    # get the model architecture\n",
    "net(X)        # execute the forward feed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
